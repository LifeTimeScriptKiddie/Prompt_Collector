={"data":"# Implementation Plan — ZeroMemory Demo Agent (Scout)\n\n## Goals\n\n* Showcase AINative **Memory for Agents** via Python SDK in a tiny, live-codable app.\n* Demonstrate **save → replay (vector+recency) → prompt injection → response**.\n* Provide obvious “with vs without memory” UX and a scoreboard of which memories were used.\n\n## Constraints & Assumptions\n\n* Use **AINative Python SDK** (wrap in a thin adapter to decouple from SDK surface changes).\n* Keep infra minimal: **FastAPI** backend + **Vite/React** SPA.\n* LLM can be local (Ollama) or a hosted endpoint; app is LLM-agnostic.\n* Works offline with a **mock SDK** if the real API key isn’t available.\n\n## High-Level Flow\n\n1. User chats → backend calls **MemoryReplay** (semantic search + recency decay) via SDK.\n2. Backend injects replayed memory into the LLM prompt → gets reply.\n3. Backend saves new memory candidates (simple extractor) via SDK.\n4. UI shows replayed memory (type, text, score) and a “Use memory” toggle.\n\n## Architecture\n\n```\nfrontend (Vite/React)\n  ├─ Chat view\n  └─ Memory panel (read-only)\n\nbackend (FastAPI)\n  ├─ /chat        -> adapter.replay() -> LLM -> adapter.add()\n  ├─ /feedback    -> adapter.feedback()\n  ├─ /memories    -> adapter.list() (for debugging/demo)\n  └─ /healthz\n\nAINativeAdapter (Python)\n  ├─ add_memory(user_id, agent_id, session_id, type, text, tags, metadata)\n  ├─ replay_memory(user_id, agent_id, session_id, query, top_k, filters, strategy)\n  ├─ list_memories(tags | session scope)\n  └─ feedback(memory_id, signal, reason)\n```\n\n## Scoring (Replay Strategy)\n\n* SDK semantic search (vector similarity) → **overfetch** K×3.\n* Re-rank with **recency decay** (half-life default: 72h).\n* Final score = `similarity * decay_weight`; take **top-k**.\n\n## Repo Structure\n\n```\nscout/\n  backend/\n    app.py\n    adapter/\n      ainative_adapter.py   # wraps the SDK\n      mock_adapter.py       # fallback for demos without API key\n    tests/\n      test_adapter.py\n      test_chat_e2e.py\n    .env.example\n  frontend/\n    src/App.tsx\n    src/components/Chat.tsx\n    src/components/MemoryPanel.tsx\n    src/lib/api.ts\n    vite.config.ts\n  README.md\n```\n\n## Environment & Config\n\n* `AINATIVE_API_KEY`, `AINATIVE_PROJECT` (if needed), `LLM_URL`, `PORT`.\n* Feature flags: `USE_MOCK_ADAPTER`, `MEMORY_HALFLIFE_HOURS`, `DEFAULT_TOP_K`.\n\n## Work Breakdown (with Est. Effort)\n\n1. **Adapter layer** (SDK + mock) — 0.5d\n\n   * Implement `add_memory`, `replay_memory`, `list_memories`, `feedback`.\n2. **Replay logic** — 0.25d\n\n   * Overfetch, recency half-life, scoring, filters (type, session/global).\n3. **FastAPI endpoints** — 0.5d\n\n   * `/chat`, `/feedback`, `/memories`, `/healthz`; error handling.\n4. **LLM client** — 0.25d\n\n   * Minimal HTTP client; prompt builder with memory block.\n5. **Frontend** — 0.75d\n\n   * Chat UI + right-side memory panel; memory toggle; top-k slider; scope switch.\n6. **Seed & scripts** — 0.25d\n\n   * `seed_memories.py`, cURL examples, demo data.\n7. **Testing** — 0.5d\n\n   * Unit tests (adapter), integration test (`/chat` with mock), smoke runbook.\n8. **Docs & Runbook** — 0.25d\n\n   * README quickstart, live-demo script, troubleshooting.\n\n*Total: \\~3.25 dev-days (one strong dev can compress to a single focused day).*\n\n## Quality Gates\n\n* **P50 /chat** ≤ 800ms (mock LLM excluded); **P95** ≤ 1500ms.\n* **Top-k replay correctness**: manual checks show expected memories appear with scores.\n* **Toggle validation**: “Use memory” OFF produces materially different, generic replies.\n\n## Telemetry & Logging\n\n* Log replay request/response (IDs, scores, counts), not raw content by default.\n* Count memory saves per session; track feedback (+1/−1) rates.\n* Frontend: record toggle state and top-k changes (console is fine for demo).\n\n## Live Demo Runbook (5–7 min)\n\n1. Cold ask (memory off): “Lunch ideas + time to review pitch?” → generic.\n2. Teach memory: “I’m vegan and hate early meetings; pitch is Friday 10am.”\n3. Ask again (memory on): replay shows vegan + Friday; reply is contextual.\n4. Show feedback (+1) on the most helpful memory.\n5. Switch scope to **Global**; demonstrate cross-session recall.\n\n## Risks & Mitigations\n\n* **SDK surface mismatch** → **Adapter** isolates changes.\n* **No API key / flaky network** → **Mock adapter** + seeded memories.\n* **LLM variance** → Fix temperature; keep prompts deterministic.\n\n---\n\n"}