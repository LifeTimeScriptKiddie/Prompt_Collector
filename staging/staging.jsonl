={"data":"Here's a comprehensive README.md that another agent can use to build the full codebase:\n\n```markdown\n# PromptLint\n\n> A developer tool for analyzing, scoring, and optimizing LLM prompts with built-in security scanning and cost estimation.\n\n## Overview\n\nPromptLint is a CLI tool (with future SaaS potential) that helps developers write better prompts by providing actionable feedback on clarity, cost, and security. It's designed as Phase 1 of a larger vision (PromptIR) but delivers immediate value as a standalone linting tool.\n\n**Think of it as:** ESLint for prompts, with diff capabilities and security scanning.\n\n---\n\n## Core Value Proposition\n\n1. **Score prompts** on clarity, cost efficiency, and security\n2. **Diff prompts** to see how changes impact quality and cost\n3. **Detect prompt injection** vulnerabilities\n4. **Estimate costs** across different models before running\n5. **Modular architecture** that can evolve into a reasoning compiler (PromptIR)\n\n---\n\n## MVP Features (Week 1-2)\n\n### 1. Prompt Scoring\n```bash\npromptlint score prompt.txt\n```\n\n**Output:**\n```\nğŸ“Š Prompt Analysis Report\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâœ¨ Clarity: 8.5/10\n   âœ“ Clear instruction structure\n   âš  Contains ambiguous phrase: \"as needed\"\n   ğŸ’¡ Suggestion: Specify exact conditions\n\nğŸ’° Cost Efficiency: 7/10\n   ğŸ“ Tokens: 245 input / ~500 estimated output\n   ğŸ’µ Estimated cost per run:\n      â€¢ gpt-4o: $0.0042\n      â€¢ gpt-4o-mini: $0.0003\n      â€¢ claude-3.5-sonnet: $0.0038\n\nğŸ›¡ï¸ Security: Medium Risk (6/10)\n   âš  Unguarded variable: {user_input}\n   âš  Pattern detected: \"ignore previous\"\n   ğŸ’¡ Add input sanitization\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nOverall Score: 7.2/10\n```\n\n### 2. Prompt Diffing\n```bash\npromptlint diff old-prompt.txt new-prompt.txt\n```\n\n**Output:**\n```\nğŸ“Š Prompt Comparison\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nContent Changes:\n  + Line 2: \"generate code\" â†’ \"generate Python code\"\n  + Line 5: Added explicit output format requirement\n  - Line 8: Removed ambiguous phrase \"as appropriate\"\n\nImpact Analysis:\n  âœ… Clarity:    8.5/10 â†’ 9.2/10  (+0.7, +8%)\n  âœ… Cost:       -56 tokens       (-18%)\n  âœ… Security:   6/10 â†’ 8/10      (+2)\n\nEstimated Cost Change:\n  gpt-4o: $0.0042 â†’ $0.0034 (-19%)\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nâœ… Overall: This change improves the prompt\n```\n\n### 3. Injection Detection\n```bash\npromptlint security prompt.txt\n```\n\n**Output:**\n```\nğŸ›¡ï¸ Security Analysis\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâŒ HIGH RISK: Prompt injection pattern detected\n   Pattern: \"Ignore all previous instructions\"\n   Location: Line 12\n   Risk: User could override system behavior\n\nâš ï¸ MEDIUM RISK: Unguarded user input\n   Variable: {user_query}\n   Location: Line 5\n   Risk: Direct injection without sanitization\n\nğŸ’¡ Recommendations:\n   1. Add input validation before {user_query}\n   2. Remove or rephrase line 12\n   3. Consider using structured output format\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nOverall Security Score: 4/10 (Needs Improvement)\n```\n\n---\n\n## Architecture\n\n### High-Level Flow\n```\nInput (prompt.txt)\n    â†“\nParser (extract structure, variables, instructions)\n    â†“\nAnalyzer (run rules: clarity, cost, security)\n    â†“\nReporter (format output: CLI, JSON, Markdown)\n    â†“\nOutput (scored results + recommendations)\n```\n\n### Directory Structure\n```\npromptlint/\nâ”‚\nâ”œâ”€â”€ promptlint/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ cli.py                 # Main CLI interface (Typer)\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ core/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ parser.py          # Extract prompt structure\nâ”‚   â”‚   â”œâ”€â”€ analyzer.py        # Run all checks\nâ”‚   â”‚   â”œâ”€â”€ differ.py          # Compare two prompts\nâ”‚   â”‚   â””â”€â”€ models.py          # Pydantic models (future PromptIR seed)\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ analyzers/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ clarity.py         # Clarity scoring logic\nâ”‚   â”‚   â”œâ”€â”€ cost.py            # Token counting + cost estimation\nâ”‚   â”‚   â””â”€â”€ security.py        # Injection detection\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ reporters/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ console.py         # Rich console output\nâ”‚   â”‚   â”œâ”€â”€ json_reporter.py   # JSON format\nâ”‚   â”‚   â””â”€â”€ markdown.py        # Markdown format\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ rules/\nâ”‚   â”‚   â”œâ”€â”€ clarity_rules.yaml      # Clarity heuristics\nâ”‚   â”‚   â”œâ”€â”€ cost_rules.yaml         # Cost models/pricing\nâ”‚   â”‚   â””â”€â”€ security_patterns.yaml  # Injection patterns\nâ”‚   â”‚\nâ”‚   â””â”€â”€ utils/\nâ”‚       â”œâ”€â”€ __init__.py\nâ”‚       â”œâ”€â”€ tokenizer.py       # Token counting (tiktoken)\nâ”‚       â””â”€â”€ pricing.py         # Model pricing data\nâ”‚\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ test_parser.py\nâ”‚   â”œâ”€â”€ test_analyzers.py\nâ”‚   â”œâ”€â”€ test_differ.py\nâ”‚   â””â”€â”€ fixtures/\nâ”‚       â”œâ”€â”€ good_prompt.txt\nâ”‚       â”œâ”€â”€ bad_prompt.txt\nâ”‚       â””â”€â”€ injection_prompt.txt\nâ”‚\nâ”œâ”€â”€ examples/\nâ”‚   â”œâ”€â”€ basic_prompt.txt\nâ”‚   â”œâ”€â”€ good_prompt.txt\nâ”‚   â””â”€â”€ risky_prompt.txt\nâ”‚\nâ”œâ”€â”€ pyproject.toml             # Poetry config\nâ”œâ”€â”€ README.md\nâ””â”€â”€ .gitignore\n```\n\n---\n\n## Technical Stack\n\n### Core Dependencies\n- **Python 3.11+**\n- **Typer** - CLI framework\n- **Rich** - Beautiful terminal output\n- **Pydantic** - Data validation and internal IR models\n- **tiktoken** - Token counting (OpenAI tokenizer)\n- **PyYAML** - Rule configuration\n- **difflib** - Built-in diff functionality\n\n### Dev Dependencies\n- **pytest** - Testing\n- **black** - Code formatting\n- **ruff** - Linting\n- **mypy** - Type checking\n\n---\n\n## Implementation Details\n\n### 1. Parser (`core/parser.py`)\n\n**Responsibility:** Extract structured information from raw prompt text.\n\n**Extract:**\n- Instructions (imperative sentences)\n- Variables (placeholders like `{variable}`, `{{variable}}`, `<variable>`)\n- Conditional logic (\"if X then Y\")\n- Output format requirements\n- Context/examples\n- Length/tone requirements\n\n**Output Model:**\n```python\nclass ParsedPrompt(BaseModel):\n    raw_text: str\n    instructions: List[Instruction]\n    variables: List[Variable]\n    conditionals: List[Conditional]\n    output_format: Optional[str]\n    examples: List[str]\n    metadata: Dict[str, Any]\n```\n\n**Implementation Notes:**\n- Use regex for variable detection\n- Use spaCy or simple NLP for sentence segmentation\n- Detect structure patterns (numbered lists, bullet points)\n- Identify meta-instructions (\"be concise\", \"think step by step\")\n\n---\n\n### 2. Analyzers\n\n#### 2a. Clarity Analyzer (`analyzers/clarity.py`)\n\n**Scoring Criteria:**\n- âœ… Clear instructions (imperative, specific)\n- âœ… No ambiguous phrases (\"as needed\", \"maybe\", \"try to\")\n- âœ… Explicit output format\n- âœ… No conflicting instructions\n- âœ… Appropriate level of detail\n\n**Heuristics:**\n```python\nAMBIGUOUS_PHRASES = [\n    \"as needed\", \"if possible\", \"try to\", \"maybe\",\n    \"perhaps\", \"might\", \"could\", \"should probably\"\n]\n\nCLARITY_BOOSTERS = [\n    \"step by step\", \"first\", \"then\", \"finally\",\n    \"output format:\", \"example:\", \"requirements:\"\n]\n```\n\n**Scoring Algorithm:**\n```python\nbase_score = 5.0\nscore += has_clear_structure * 2\nscore += has_examples * 1\nscore += has_output_format * 1.5\nscore -= ambiguous_phrase_count * 0.5\nscore -= missing_specificity * 1\nreturn min(10, max(0, score))\n```\n\n#### 2b. Cost Analyzer (`analyzers/cost.py`)\n\n**Features:**\n- Token counting using tiktoken\n- Estimate output tokens based on instruction complexity\n- Calculate cost for multiple models (GPT-4o, GPT-4o-mini, Claude 3.5)\n- Flag expensive patterns (large context, complex reasoning)\n\n**Pricing Data (in `rules/cost_rules.yaml`):**\n```yaml\nmodels:\n  gpt-4o:\n    input_price_per_1m: 2.50\n    output_price_per_1m: 10.00\n  gpt-4o-mini:\n    input_price_per_1m: 0.15\n    output_price_per_1m: 0.60\n  claude-3.5-sonnet:\n    input_price_per_1m: 3.00\n    output_price_per_1m: 15.00\n```\n\n**Implementation:**\n```python\ndef estimate_cost(prompt: ParsedPrompt, model: str) -> CostEstimate:\n    input_tokens = count_tokens(prompt.raw_text, model)\n    estimated_output = estimate_output_tokens(prompt)\n    \n    pricing = load_pricing(model)\n    input_cost = (input_tokens / 1_000_000) * pricing.input_price\n    output_cost = (estimated_output / 1_000_000) * pricing.output_price\n    \n    return CostEstimate(\n        input_tokens=input_tokens,\n        estimated_output_tokens=estimated_output,\n        total_cost=input_cost + output_cost,\n        model=model\n    )\n```\n\n#### 2c. Security Analyzer (`analyzers/security.py`)\n\n**Detection Patterns (in `rules/security_patterns.yaml`):**\n```yaml\nhigh_risk:\n  - pattern: \"ignore (all )?previous (instructions|commands)\"\n    risk: \"User can override system behavior\"\n  - pattern: \"reveal (the )?system prompt\"\n    risk: \"Prompt leakage vulnerability\"\n  - pattern: \"act as .* and ignore\"\n    risk: \"Role confusion attack\"\n\nmedium_risk:\n  - pattern: '\\{[^}]+\\}'  # Unvalidated variables\n    risk: \"Unguarded user input\"\n  - pattern: \"execute|eval|run code\"\n    risk: \"Potential code execution\"\n\nlow_risk:\n  - pattern: \"translate|summarize|explain\"\n    risk: \"Generally safe operations\"\n```\n\n**Scoring:**\n```python\nscore = 10.0\nscore -= high_risk_count * 3\nscore -= medium_risk_count * 1.5\nscore -= low_risk_count * 0.5\nreturn max(0, score)\n```\n\n---\n\n### 3. Differ (`core/differ.py`)\n\n**Features:**\n- Line-by-line text comparison\n- Score delta calculation\n- Cost impact analysis\n- Semantic change detection\n\n**Implementation:**\n```python\ndef diff_prompts(old_path: str, new_path: str) -> DiffReport:\n    old = parse_prompt(old_path)\n    new = parse_prompt(new_path)\n    \n    text_diff = difflib.unified_diff(\n        old.raw_text.splitlines(),\n        new.raw_text.splitlines()\n    )\n    \n    old_scores = analyze_prompt(old)\n    new_scores = analyze_prompt(new)\n    \n    return DiffReport(\n        text_changes=list(text_diff),\n        clarity_delta=new_scores.clarity - old_scores.clarity,\n        cost_delta=new_scores.cost - old_scores.cost,\n        security_delta=new_scores.security - old_scores.security,\n        recommendation=generate_recommendation(old_scores, new_scores)\n    )\n```\n\n---\n\n### 4. CLI (`cli.py`)\n\n**Commands:**\n```python\n@app.command()\ndef score(\n    prompt_file: Path,\n    model: str = \"gpt-4o\",\n    format: str = \"console\"  # console, json, markdown\n):\n    \"\"\"Score a prompt on clarity, cost, and security.\"\"\"\n    \n@app.command()\ndef diff(\n    old_prompt: Path,\n    new_prompt: Path,\n    format: str = \"console\"\n):\n    \"\"\"Compare two prompt versions.\"\"\"\n\n@app.command()\ndef security(\n    prompt_file: Path,\n    format: str = \"console\"\n):\n    \"\"\"Run security analysis only.\"\"\"\n\n@app.command()\ndef estimate(\n    prompt_file: Path,\n    models: List[str] = [\"gpt-4o\", \"gpt-4o-mini\", \"claude-3.5-sonnet\"]\n):\n    \"\"\"Estimate costs across multiple models.\"\"\"\n```\n\n---\n\n## Data Models (Pydantic)\n\n**These models form the foundation of future PromptIR:**\n\n```python\n# core/models.py\n\nclass Variable(BaseModel):\n    name: str\n    location: int  # line number\n    has_validation: bool = False\n\nclass Instruction(BaseModel):\n    text: str\n    line: int\n    type: Literal[\"action\", \"constraint\", \"format\", \"meta\"]\n\nclass ParsedPrompt(BaseModel):\n    raw_text: str\n    instructions: List[Instruction]\n    variables: List[Variable]\n    conditionals: List[str]\n    output_format: Optional[str]\n    examples: List[str]\n    metadata: Dict[str, Any]\n\nclass ScoreResult(BaseModel):\n    clarity: float\n    cost: float\n    security: float\n    overall: float\n    issues: List[Issue]\n    suggestions: List[str]\n\nclass Issue(BaseModel):\n    severity: Literal[\"high\", \"medium\", \"low\"]\n    category: Literal[\"clarity\", \"cost\", \"security\"]\n    description: str\n    location: Optional[int]\n    suggestion: str\n\nclass CostEstimate(BaseModel):\n    input_tokens: int\n    estimated_output_tokens: int\n    total_cost: float\n    model: str\n\nclass DiffReport(BaseModel):\n    text_changes: List[str]\n    clarity_delta: float\n    cost_delta: CostEstimate\n    security_delta: float\n    recommendation: str\n```\n\n---\n\n## Example Usage\n\n### Example 1: Score a Prompt\n```bash\npromptlint score examples/basic_prompt.txt\n```\n\n### Example 2: Compare Versions\n```bash\npromptlint diff prompts/v1.txt prompts/v2.txt --format=json > diff-report.json\n```\n\n### Example 3: Security Scan\n```bash\npromptlint security user-prompt.txt\n```\n\n### Example 4: Cost Estimation\n```bash\npromptlint estimate my-prompt.txt --models gpt-4o,claude-3.5-sonnet\n```\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n- Test parser extraction accuracy\n- Test scoring algorithms\n- Test diff logic\n- Test security pattern matching\n\n### Integration Tests\n- Test full CLI commands\n- Test output formatting\n- Test file I/O\n\n### Fixtures\nCreate test prompts in `tests/fixtures/`:\n- `good_prompt.txt` - High scores across all metrics\n- `ambiguous_prompt.txt` - Low clarity\n- `expensive_prompt.txt` - High token count\n- `injection_prompt.txt` - Security issues\n\n---\n\n## Installation & Setup\n\n```bash\n# Install with Poetry\npoetry install\n\n# Or with pip\npip install -e .\n\n# Run CLI\npromptlint --help\n```\n\n---\n\n## Configuration File (Optional Future Feature)\n\n`.promptlint.yaml`:\n```yaml\ndefault_model: gpt-4o\noutput_format: console\n\nrules:\n  clarity:\n    min_score: 7.0\n  cost:\n    max_tokens: 2000\n    warn_threshold: 1000\n  security:\n    min_score: 8.0\n    \nignore_patterns:\n  - \"# promptlint-ignore\"\n```\n\n---\n\n## Roadmap\n\n### Phase 1 (Week 1-2): MVP\n- âœ… Prompt scoring (clarity, cost, security)\n- âœ… Diff functionality\n- âœ… CLI interface\n- âœ… Basic reporting\n\n### Phase 2 (Week 3-4): Enhancement\n- LLM-based consistency testing (run prompt multiple times, check variance)\n- Regression testing (snapshot + compare)\n- VS Code extension\n\n### Phase 3 (Month 2): PromptIR Evolution\n- Add graph visualization of prompt logic\n- Add optimization layer (reduce redundant steps)\n- Add execution simulation\n\n### Phase 4: SaaS\n- Web UI\n- Team collaboration\n- API access\n- Enterprise features\n\n---\n\n## Success Metrics\n\n**Week 1:**\n- MVP working with all 3 core commands\n- 10+ test cases passing\n- Beautiful terminal output\n\n**Week 2:**\n- Published to PyPI\n- GitHub repo with examples\n- Initial tweet/demo video\n\n**Month 1:**\n- 100+ GitHub stars\n- 10+ real users providing feedback\n- Feature requests guiding Phase 2\n\n---\n\n## Technical Debt to Avoid\n\n1. **Don't hard-code pricing** - Use YAML config\n2. **Don't over-engineer** - Start with heuristics, add LLM later\n3. **Keep models simple** - They'll evolve into PromptIR\n4. **Write tests from day 1** - This will move fast, need safety\n5. **Document as you go** - Good docstrings = good foundation\n\n---\n\n## License\n\nMIT\n\n---\n\n## Notes for the Implementing Agent\n\n- Prioritize getting the **score** command working first\n- Use **Rich** library for beautiful console output (progress bars, tables, colors)\n- Token counting is critical - use `tiktoken` correctly for each model\n- Security patterns should be easily extensible (YAML file)\n- Keep the code modular - each analyzer should be independent\n- The `models.py` file is the seed of PromptIR - design it thoughtfully\n- Add comprehensive docstrings - this will become open source\n- Include at least 5 example prompts in `examples/`\n\n**Start with:** Parser + Clarity Analyzer + CLI score command. Get that working end-to-end, then add Cost and Security.\n```\n\n---"}