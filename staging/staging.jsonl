{
  "data": "# Available Models for Benchmarking\n\nThis document lists the Groq models that can be used with the benchmark script.\n\n## Prompt Injection Detection Models\n\n### GPT-OSS-Safeguard (20B)\n**Model ID:** `openai/gpt-oss-safeguard-20b`\n\nPurpose-built for detecting prompt injection attacks and jailbreak attempts.\n\n**Features:**\n- Supports `reasoning_effort` parameter (`low`, `medium`, `high`)\n- Optimized for security classification tasks\n- Returns structured JSON responses for violation detection\n- Uses system prompt with embedded detection policy\n\n**Prompt Format (automatic):**\n- System message: Full detection policy with input embedded\n- User message: \"Please analyze the content above.\"\n\n**Example:**\n```bash\nuv run python benchmark_groq.py \\\n  --model openai/gpt-oss-safeguard-20b \\\n  --dataset datasets/jailbreaks_english.json \\\n  --reasoning-effort low \\\n  --max-concurrency 10\n```\n\n### Llama Prompt Guard (86M)\n**Model ID:** `meta-llama/llama-prompt-guard-2-86m`\n\nLightweight model specifically designed for prompt injection detection.\n\n**Features:**\n- Very fast inference (small 86M parameter model)\n- Direct classification of prompt safety\n- Low latency for real-time filtering\n\n**Example:**\n```bash\nuv run python benchmark_groq.py \\\n  --model meta-llama/llama-prompt-guard-2-86m \\\n  --dataset datasets/jailbreaks_english.json \\\n  --max-concurrency 10\n```\n\n## General-Purpose Language Models\n\n### Llama 3.1 8B Instant\n**Model ID:** `llama-3.1-8b-instant`\n\nFast, efficient general-purpose language model adapted for prompt injection detection.\n\n**Features:**\n- Excellent multilingual capabilities (English, Japanese, etc.)\n- Optimized for low latency (\"instant\" variant)\n- Can be prompted for security classification tasks\n- 8B parameters - balanced size/performance\n- Uses user prompt format (no system message)\n\n**Prompt Format (automatic):**\n- Single user message with embedded instructions, examples, and input\n- No system prompt (for optimal model compatibility)\n\n**Example:**\n```bash\n# English benchmark\nuv run python benchmark_groq.py \\\n  --model llama-3.1-8b-instant \\\n  --dataset datasets/jailbreaks_english.json \\\n  --max-concurrency 10\n\n# Japanese benchmark\nuv run python benchmark_groq.py \\\n  --model llama-3.1-8b-instant \\\n  --dataset datasets/jailbreaks_japanese.json \\\n  --max-concurrency 10\n\n# Multi-language comparison\nuv run python benchmark_groq.py \\\n  --model llama-3.1-8b-instant \\\n  --datasets datasets/jailbreaks_english.json datasets/jailbreaks_japanese.json \\\n  --max-concurrency 10\n```\n\n### Llama 3.1 70B Versatile\n**Model ID:** `llama-3.1-70b-versatile`\n\nLarger, more capable model with enhanced reasoning abilities.\n\n**Features:**\n- Superior performance on complex tasks\n- Better multilingual understanding\n- Higher latency than 8B model but more accurate\n- 70B parameters - larger context understanding\n\n**Example:**\n```bash\nuv run python benchmark_groq.py \\\n  --model llama-3.1-70b-versatile \\\n  --dataset datasets/jailbreaks_english.json \\\n  --max-concurrency 5\n```"
}
