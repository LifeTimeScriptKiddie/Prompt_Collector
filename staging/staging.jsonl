={"data":"### Surveys \n\n#### LLM Backdoors\n- [2025/02] **A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations** - [arXiv](https://arxiv.org/abs/2502.05224)\n- [2024/06] **A Survey of Recent Backdoor Attacks and Defenses in Large Language Models** - [arXiv](https://arxiv.org/abs/2406.06852)\n- [2025/12] **Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review** - [arXiv](https://arxiv.org/abs/2309.06055)\n\n\n#### Red Teaming\n- [2025/03] **Building Safe GenAI Applications: An End-to-End Overview of Red Teaming for Large Language Models** - [arXiv](https://arxiv.org/abs/2503.01742)\n- [2025/04] **Against The Achillesâ€™ Heel: A Survey on Red Teaming for Generative Models** - [JAIR](https://www.jair.org/index.php/jair/article/view/17654)\n\n#### LLM Security\n- [2025/05] **LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures** - [arXiv](https://arxiv.org/abs/2505.01177)\n- [2025/05] **Attack and Defense Techniques in Large Language Models: A Survey and New Perspectives** - [arXiv](https://arxiv.org/abs/2505.00976)\n\n#### Attacks/Defenses\n- [2025/05] **A Survey of Attacks on Large Language Models** - [arXiv](https://arxiv.org/abs/2505.12567)\n- [2025/06] **From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem** - [arXiv](https://arxiv.org/abs/2506.15170)\n\n#### Threats & Misuse\n- [2025/05] **Security Concerns for Large Language Models: A Survey** - [arXiv](https://arxiv.org/abs/2505.18889)\n\n#### Data/Model Poisoning\n- [2025/06] **A Systematic Review of Poisoning Attacks Against Large Language Models** - [arXiv](https://arxiv.org/abs/2506.06518)\n\n#### Model Extraction\n- [2025/06] **A Survey on Model Extraction Attacks and Defenses for Large Language Models** - [arXiv](https://arxiv.org/abs/2506.22521)\n\n#### Agent Threat Model\n- [2025/05] **Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks** - [arXiv](https://arxiv.org/abs/2505.12786)\n- [2025/06] **From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows** - [arXiv](https://arxiv.org/abs/2506.23260)\n- [2025/06] **A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures** - [arXiv](https://arxiv.org/abs/2506.19676)\n- [2025/03] **A Survey on Trustworthy LLM Agents: Threats and Countermeasures** - [arXiv](https://arxiv.org/abs/2503.09648)\n- [2024/09] **AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways** - [arXiv](https://arxiv.org/abs/2406.02630)\n  \n#### Data Security\n- [2025/08] **A Survey on Data Security in Large Language Models** - [arXiv](https://arxiv.org/abs/2508.02312)\n\n#### Prompt Injection Threat Model\n- [2025/09] **A Threat Model of Prompt-Based Attacks for Securing LLMs** - [arXiv](https://arxiv.org/abs/2509.04615)\n\n#### Cross-Domain Overviews\n- [2025/04] **Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey** - [arXiv](https://arxiv.org/abs/2504.15622)\n- [2025/09] **Large Language Models in Cybersecurity: A Survey of Applications, Vulnerabilities, and Defense Techniques** - [MDPI](https://www.mdpi.com/2673-2688/6/9/216)\n\n#### SoK (Systematization of Knowledge)\n- [2025/05] **SoK: Large Language Models in Security Code Review and Testing** - [OpenReview](https://openreview.net/forum?id=hMkoe4C44D)\n- [2025/06] **SoK: Evaluating Jailbreak Guardrails for Large Language Models** - [arXiv](https://arxiv.org/abs/2506.10597)\n- [2025/08] **SoK: Large Language Model-Generated Textual Phishing** - [arXiv](https://arxiv.org/abs/2508.21457)\n"}