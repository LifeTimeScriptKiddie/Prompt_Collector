{
  "data": "Review all of the Reference Documentation in this project. It is all located within the `reference-docs` directory. I've included guidance, and technical direction from a number of different sources. All of the information is specific to building Agentic systems. Here's a list of what's available, along with brief descriptions:\n\n## Anthropic\n### Building Effective Agents\nA clear, practical guide to building systems that combine multiple LLM calls with a focus on workflows. Includes detaield descriptions of five different workflow patterns. Discusses \"agentic systems\" as a parent term, then defines a distinction between \"workflows\" - systems where multiple LLMs are orchestrated together using pre-defined patterns - and \"agents\", where the LLMs \"dynamically direct their own processes and tool usage\". This second definition is later expanded with this delightfully clear description:\n\n> Agents begin their work with either a command from, or interactive discussion with, the human user. Once the task is clear, agents plan and operate independently, potentially returning to the human for further information or judgement. During execution, it's crucial for the agents to gain “ground truth” from the environment at each step (such as tool call results or code execution) to assess its progress. Agents can then pause for human feedback at checkpoints or when encountering blockers. The task often terminates upon completion, but it’s also common to include stopping conditions (such as a maximum number of iterations) to maintain control.\n\n### How We Built our Multi-agent Research System\nThis start strong by providing a clear definition of how they'll be using the term \"agent\" - it's the \"tools in a loop\" variant:\n\n> A multi-agent system consists of multiple agents (LLMs autonomously using tools in a loop) working together. Our Research feature involves an agent that plans a research process based on user queries, and then uses tools to create parallel agents that search for information simultaneously.\n\nSomething else to consider: The prompts for this multi-agent research system may be found in the reference-docs/examples/prompts directory\n\n## Arxiv\n### Design Patterns for Securing LLM Agents agains Prompt Injections.\nThis new paper by 11 authors from organizations including IBM, Invariant Labs, ETH Zurich, Google and Microsoft is an excellent addition to the literature on prompt injection and LLM security.\n\n> In this work, we describe a number of design patterns for LLM agents that significantly mitigate the risk of prompt injections. These design patterns constrain the actions of agents to explicitly prevent them from solving arbitrary tasks. We believe these design patterns offer a valuable trade-off between agent utility and security.\n\n## Examples\nThis is a folder of examples from the Open AI Agent SDK Github Repo. There are some good patterns within. The `research_bot` and `financial_research_agent` are the most complete, but they lack certain functionality like Guardrails. Unserstand the examples as a whole.\n\nAnother folder to pay attention to here is `prompts`. it contains the prompts for Anthropics multi-agent research system.\n\n## OpenAI\n### OpenAI Agents SDK\nThis is the full documentation for OpenAI's python library `openai-agents`. This is a replacement for their previous `swarm` research project. The `openai-agents` sdk will be the primary library for the project I'm working on. Read this documentation in detail.\n\n### A Practical Guide to Building Agents\nFrom the synopsis: This guide is designed for product and engineering teams exploring how to build their first agents, distilling insights from numerous customer deployments into practical and actionable best practices. It includes frameworks for identifying promising use cases, clear patterns for designing agent logic and orchestration, and best practices to ensure your agents run safely, predictably, and effectively.\n\n## Willison\nSimon Willison is a developer, speaker, and open-source advocate best known for his recent work making large language models (LLMs) more accessible and useful for developers, journalists, and researchers. He is the creator of Datasette, a powerful tool for publishing structured data, and LLM, a command-line utility and Python library that enables seamless interaction with LLM APIs like OpenAI, Anthropic, and Claude.\n\n### The Lethal Trifecta for AI Agents\nIn this paper, Simon highlights the dangers of Agentic systems in production. \"If you are a user of LLM systems that use tools (you can call them “AI agents” if you like) it is critically important that you understand the risk of combining tools with the following three characteristics. Failing to understand this can let an attacker steal your data.\"\n\n---\n\nReview in detail all of this information. My intent is to keep all of this in mind while building my first agentic system designed for production. I will be using Claude Code almost exclusively for this effort. Your task:\n\n 1. Ultrathink\n 2. Consume this vast corpus of data\n 3. Recognize intrinsic details, and common patterns from the various sources\n 4. Summarize into a single markdown file that captures in detail:\n     a. Security Considerations\n     b. Robust patterns for mitigating prompt injection\n     c. A robust understanding of the OpenAI Agents SDK\n\nThis markdown document will be used as a foundation for all future work related to building this agentic system with Claude Code."
}
