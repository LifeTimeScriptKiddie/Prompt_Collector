{
  "data": "# Subtitle App Memory ‚Äì April 2025\n\n## Purpose\n\nBuild a UI for memory automation of ChatGPT chats.\n\n## Key Points\n\n- Uses local models via Ollama\n- Streamlit-based app\n- Stores memory shards locally\n\n## Tags\n\n#language #gpt #project #subtitle\n\n# ChatGPT Memory Automation - Project Initialization\n\n# Profile: ChatGPT Memory Automation\n\n# This profile sets up the environment, dependencies, and structure for your memory assistant app.\n\n# 1. Project Folder Structure Suggestion\n\nproject_structure = \"\"\"\nCChatGPT-Memory-Automation/\n‚îú‚îÄ‚îÄ app.py\n‚îú‚îÄ‚îÄ config.py\n‚îú‚îÄ‚îÄ memory/\n‚îú‚îÄ‚îÄ database/\n‚îÇ ‚îî‚îÄ‚îÄ init_db.py\n‚îú‚îÄ‚îÄ utils/\n‚îú‚îÄ‚îÄ assets/\n‚îú‚îÄ‚îÄ requirements.txt\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ .env\n\"\"\"\n\n# 2. Environment Setup: Create a Python virtual environment (Unix-based shell)\n\nshell_setup_commands = \"\"\"\n\n# Create virtual environment\n\npython3 -m venv .venv\n\n# Activate it\n\nsource .venv/bin/activate\n\n# Install required packages\n\npip install streamlit openai sqlite-utils typer python-dotenv\n\n# Freeze dependencies\n\npip freeze > requirements.txt\n\"\"\"\n\n# 3. .gitignore Suggestions\n\ngitignore_content = \"\"\"\n.venv/\n**pycache**/\n.env\n_.db\nmemory/_.txt\nmemory/\\*.json\n\"\"\"\n\n# 4. README.md Bootstrap\n\nreadme_intro = \"\"\"\n\n# ChatGPT Memory Automation üß†üíæ\n\nA Streamlit-based personal memory assistant that:\n\n- Stores and manages summaries of your ChatGPT chats\n- Allows prompt injection based on local memory files\n- Supports keyword search and memory indexing\n- Optional summarization via local LLMs or OpenAI API\n\n## Quickstart\n\n1. Clone the repo\n2. Create a virtual environment\n3. Run `streamlit run app.py`\n   \"\"\"\n\n# 5. Initial Placeholder Code for app.py\n\napp_placeholder = \"\"\"\nimport streamlit as st\nfrom config import \\*\n\nst.set_page_config(page_title=PROJECT_NAME)\n\nst.title(PROJECT_NAME)\nst.write(DESCRIPTION)\n\nst.sidebar.title(\"üìÅ Project Profile\")\nst.sidebar.markdown(f\"**Project**: {PROJECT_NAME}\")\nst.sidebar.markdown(f\"**Version**: {VERSION}\")\nst.sidebar.markdown(f\"**Author**: {AUTHOR}\")\nst.sidebar.markdown(f\"**Model**: {'Local - ' + LOCAL_MODEL_NAME if USE_LOCAL_MODEL else 'OpenAI - ' + OPENAI_MODEL}\")\nst.sidebar.markdown(f\"**Summary Format**: {DEFAULT_SUMMARY_FORMAT}\")\n\"\"\"\n\n# 6. Config File: config.py\n\nconfig_file = \"\"\"\nfrom pathlib import Path\n\nPROJECT_NAME = \"ChatGPT Memory Automation\"\nVERSION = \"0.1\"\nAUTHOR = \"Kazi\"\nDESCRIPTION = \"Streamlit app to manage, summarize, and retrieve ChatGPT memory summaries.\"\n\nBASE_DIR = Path(**file**).resolve().parent\nMEMORY_DIR = BASE_DIR / \"memory\"\nDB_PATH = BASE_DIR / \"database\" / \"memory.db\"\nENV_PATH = BASE_DIR / \".env\"\n\nUSE_LOCAL_MODEL = True\nLOCAL_MODEL_NAME = \"mistral\"\nUSE_OPENAI = False\nOPENAI_MODEL = \"gpt-3.5-turbo\"\n\nDEFAULT_SUMMARY_FORMAT = \"json\"\nSUMMARY_TAGS = [\"project\", \"goal\", \"tech\", \"todo\"]\n\"\"\"\n\nprint(\"Project structure created. Next steps:\")\nprint(\"1. Create folders and files as listed above\")\nprint(\"2. Set up your environment with the shell commands\")\nprint(\"3. Populate README.md and .gitignore\")\nprint(\"4. Add config.py for your project profile\")\nprint(\"5. Start developing in app.py\")\n"
}
