{
  "data": "# Online Shopping Agent\n\n## Architecture Overview\n\nThe following diagram illustrates the high-level architecture and workflow of the online shopping agent (It is quite self-explanatory and provides a clear overview of how the system works.):\n\n![Architecture Diagram](./online-shopping-agent.svg)\n\n## Use Cases\n\n| Category | Use Cases | Status |\n|----------|-----------|--------|\n| **Handled** | Query Processing | ✅ |\n| | - Cleaning user queries | ✅ |\n| | - Validating user queries | ✅ |\n| | - Structuring user queries | ✅ |\n| | Product Scraping | ✅ |\n| | - Parallel scraping from multiple platforms | ✅ |\n| | - Standardized JSON output | ✅ |\n| | - Product details (image, price, discount, platform) | ✅ |\n| **Unhandled** | Real-time Updates | ❌ |\n| | - Live progress updates during scraping | ❌ |\n| | - Browser-based streaming of LLM responses | ❌ |\n| | Log Processing | ❌ |\n| | - File watcher service for log changes | ❌ |\n| | - Custom log parser for non-standard formats | ❌ |\n| | Product Search | ❌ |\n| | - Pagination through all available products | ❌ |\n\n## User Interface Design\n\nThe application features a clean, minimalist interface designed for easy product discovery and comparison:\n\n### Search Interface\n- A search bar at the top with a search icon\n- Natural language query support (e.g., \"Find some cotton cargo pants under Rs. 1000\")\n\n### Product Display\n![UI Design Sketch](./online-shopping-agent.png)\n- Products are displayed in a responsive grid layout\n- Each product card contains:\n  - Product image\n  - Product name\n  - Current price in INR (₹)\n  - Original price (strikethrough when discounted)\n  - Discount badge (e.g., \"65% OFF\", \"25% OFF\") in red\n  - Platform/marketplace icon (e.g., Myntra, Amazon)\n  - \"BUY NOW\" action button\n\nThe design prioritizes clarity and comparison shopping, making it easy for users to quickly scan multiple options across different platforms and make informed purchasing decisions.\n\n### UX Considerations\n\n#### Loading States and Real-time Feedback\n- The product search and scraping process takes considerable time.\n- Currently implemented: Basic skeleton loader for loading state\n- Initially planned but not implemented: Live status updates during the search process\n  - Real-time updates about which platforms are being searched\n  - Progress indicators for data collection\n  - Immediate display of products as they are found\n  - Status messages about query processing and data validation\n\n#### Implementation Challenges\n- Technical Limitations:\n  - Browser-use package limitations streaming of events\n  - No built-in support for real-time status updates\n- Resource Constraints:\n  - Custom implementation would require:\n    - File watcher service to monitor log updates\n    - Custom log parser for structured data\n    - UI components for streaming updates\n  - These features were deprioritized due to time constraints\n  - Current implementation uses a simpler loading state pattern\n\n### Browser Automation Approach\n\n#### Initial Consideration: Custom AI Browser Automation\n- Planned to build an AI-powered automation system:\n  - Using Playwright as the browser control foundation\n  - Implementing AI for understanding page structure\n  - Creating bounding boxes for element detection\n  - Using LLM for element interaction decisions\n  - Building autonomous navigation capabilities\n- Development Complexity:\n  - Building robust element detection systems\n  - Significant development time investment\n\n#### Adopted Solution: Browser-Use\n- [Browser Use = state of the art Web Agent](https://browser-use.com/posts/sota-technical-report):\n  - 89.1% success rate on WebVoyager benchmark\n  - Tested across 586 diverse web tasks\n  - Exceptional performance across major platforms:\n    - E-commerce (Amazon: 92% success rate)\n    - Search engines (Google Search: 90% success rate)\n    - Travel sites (Booking.com: 80% success rate)\n- Ready-to-use AI-powered automation:\n  - Pre-built LLM-powered navigation\n  - Existing vision-language integration\n  - Mature element detection system\n  - Proven autonomous browsing capabilities\n- Benefits of adoption:\n  - Immediate implementation\n  - Production-ready solution\n  - Fully open-source\n  - Active community support\n  - Focus on core product features\n\nThe discovery of browser-use eliminated the need to build a custom AI automation system, providing a battle-tested solution with proven performance across diverse web platforms.\n\n\n\n### Prompt Engineering\n\n#### Initial Approach\n- Direct user query forwarding to LLM\n- Challenges faced:\n  - Vague and ambiguous user queries\n  - Potential for prompt injection attacks\n  - Inconsistent search results\n  - Poor performance with unstructured queries\n\n#### Enhanced Prompt Architecture\n- Implemented a two-stage agent system:\n  1. Query Processing Agent\n     - Cleans and sanitizes user input\n     - Validates query safety\n     - Detects and prevents prompt injection attempts\n     - Structures vague queries into standardized format\n  2. Search Agent\n     - Receives structured JSON from processing agent\n     - Constructs optimized search strings\n     - Ensures consistent product discovery across platforms\n\nThis structured approach:\n- Improves search accuracy\n- Prevents security vulnerabilities\n- Handles edge cases gracefully\n- Standardizes product discovery across platforms\n- Reduces failed searches due to vague queries\n\n### Browser-Use Agent Limitations\n\n#### Schema Context Issues\n- Initial Implementation Challenge:\n  - Even with JSON schema provided to the main agent\n  - Browser-use agents run in isolated contexts\n  - Schema information wasn't propagated to scraping contexts\n  - Resulted in missing or null values for required fields\n\n#### Data Collection Inconsistencies\n- Observed Issues:\n  - Incomplete product information\n  - Inconsistent data structure\n  - Missing required fields\n  - Null values for essential attributes\n\n#### Implemented Solution\n- Embedded schema information in task description\n  - Added JSON schema directly in scraping task prompt\n  - Ensures scraping agent has complete context\n  - Guides the LLM during data collection\n- Results:\n  - More reliable data extraction\n  - Consistent schema adherence\n  - Better quality product information\n\nThis solution significantly improved the reliability of data collection.\n\n"
}
