={"data":"# Inspeq Python SDK\n\n- **Website:** [Inspeq.ai](https://www.inspeq.ai)\n- **Inspeq App:** [Inspeq App](https://platform.inspeq.ai)\n- **Detailed Documentation:** [Inspeq Documentation](https://docs.inspeq.ai)\n\n## Quickstart Guide\n\n### Installation\n\nInstall the Inspeq SDK and python-dotenv using pip:\n\n```bash\npip install inspeqai python-dotenv\n```\n\nThe `python-dotenv` package is recommended for securely managing your environment variables, such as API keys.\n\n### Obtain SDK API Key and Project Key\n\nGet your API key and Project Key from the [Inspeq App](https://platform.inspeq.ai)\n\n### Usage\n\nHere's a basic example of how to use the Inspeq SDK with environment variables:\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom inspeq.client import InspeqEval\n\n# Load environment variables\nload_dotenv()\n\n# Initialize the client\nINSPEQ_API_KEY = os.getenv(\"INSPEQ_API_KEY\")\nINSPEQ_PROJECT_ID = os.getenv(\"INSPEQ_PROJECT_ID\")\nINSPEQ_API_URL = os.getenv(\"INSPEQ_API_URL\")  # Required only for our on-prem customers\n\ninspeq_eval = InspeqEval(inspeq_api_key=INSPEQ_API_KEY, inspeq_project_id=INSPEQ_PROJECT_ID)\n\n# Prepare input data\ninput_data = [{\n    \"prompt\": \"What is the capital of France?\",\n    \"response\": \"Paris is the capital of France.\",\n    \"context\": \"The user is asking about European capitals.\"\n}]\n\n# Define metrics to evaluate\nmetrics_list = [\"RESPONSE_TONE\", \"FACTUAL_CONSISTENCY\", \"ANSWER_RELEVANCE\"]\n\ntry:\n    results = inspeq_eval.evaluate_llm_task(\n        metrics_list=metrics_list,\n        input_data=input_data,\n        task_name=\"capital_question\"\n    )\n    print(results)\nexcept Exception as e:\n    print(f\"An error occurred: {str(e)}\")\n```\n\nMake sure to create a `.env` file in your project root with your Inspeq credentials:\n\n```\nINSPEQ_API_KEY=your_inspeq_sdk_key\nINSPEQ_PROJECT_ID=your_project_id\nINSPEQ_API_URL=your_inspeq_backend_url\n```\n\n### Available Metrics \n\n```python\nmetrics_list = [\n    \"RESPONSE_TONE\",\n    \"ANSWER_RELEVANCE\",\n    \"FACTUAL_CONSISTENCY\",\n    \"CONCEPTUAL_SIMILARITY\",\n    \"READABILITY\",\n    \"COHERENCE\",\n    \"CLARITY\",\n    \"DIVERSITY\",\n    \"CREATIVITY\",\n    \"NARRATIVE_CONTINUITY\",\n    \"GRAMMATICAL_CORRECTNESS\",\n    \"DATA_LEAKAGE\",\n    \"COMPRESSION_SCORE\",\n    \"FUZZY_SCORE\",\n    \"ROUGE_SCORE\",\n    \"BLEU_SCORE\",\n    \"METEOR_SCORE\",\n    \"COSINE_SIMILARITY_SCORE\",\n    \"INSECURE_OUTPUT\",\n    \"INVISIBLE_TEXT\",\n    \"TOXICITY\",\n    \"PROMPT_INJECTION\"\n]\n```\n\n# Features\n\n\n\nThe Inspeq SDK provides a range of metrics to evaluate language model outputs:\n\n## Response Tone\nAssesses the tone and style of the generated response.\n\n## Answer Relevance\nMeasures the degree to which the generated content directly addresses and pertains to the specific question or prompt provided by the user.\n\n## Factual Consistency\nMeasures the extent of the model hallucinating i.e. model is making up a response based on its imagination or response is grounded in the context supplied.\n\n## Conceptual Similarity\nMeasures the extent to which the model response aligns with and reflects the underlying ideas or concepts present in the provided context or prompt.\n\n## Readability\nAssesses whether the model response can be read and understood by the intended audience, taking into account factors such as vocabulary complexity, sentence structure, and overall clarity.\n\n## Coherence\nEvaluates how well the model generates coherent and logical responses that align with the context of the question.\n\n## Clarity\nAssesses the response's clarity in terms of language and structure, based on grammar, readability, concise sentences and words, and less redundancy or diversity.\n\n## Diversity\nAssesses the diversity of vocabulary used in a piece of text.\n\n## Creativity\nAssesses the ability of the model to generate imaginative, and novel responses that extend beyond standard or expected answers.\n\n## Narrative Continuity\nMeasures the consistency and logical flow of the response throughout the generated text, ensuring that the progression of events remains coherent and connected.\n\n## Grammatical Correctness\nChecks whether the model response adherence to the rules of syntax, is free from errors and follows the conventions of the target language.\n\n## Prompt Injection\nEvaluates the susceptibility of language models or AI systems to adversarial prompts that manipulate or alter the system's intended behavior.\n\n## Data Leakage\nMeasures the extent to which sensitive or unintended information is exposed during model training or inference.\n\n## Insecure Output\nDetects whether the response contains insecure or dangerous code patterns that could lead to potential security vulnerabilities.\n\n## Invisible Text\nEvaluates if the input contains invisible or non-printable characters that might be used maliciously to hide information or manipulate the model's behavior.\n\n## Toxicity\nEvaluates the level of harmful or toxic language present in a given text.\n\n## BLEU Score\nMeasures the quality of text generated by models by comparing it to one or more reference texts.\n\n## Compression Score\nMeasures the ratio of the length of the generated summary to the length of the original text.\n\n## Cosine Similarity Score\nMeasures the similarity between the original text and the generated summary by treating both as vectors in a multi-dimensional space.\n\n## Fuzzy Score\nMeasures the similarity between two pieces of text based on approximate matching rather than exact matching.\n\n## METEOR Score\nEvaluates the quality of generated summaries by comparing them to reference summaries, considering matches at the level of unigrams and accounting for synonyms and stemming.\n\n## ROUGE Score\nA set of metrics used to evaluate the quality of generated summaries by comparing them to one or more reference summaries.\n\n\n## Advanced Usage\n\n### Custom Configurations\n\nYou can provide custom configurations for metrics:\n\n```python\nmetrics_config = {\n    \"response_tone_config\": {\n        \"threshold\": 0.5,\n        \"custom_labels\": [\"Negative\", \"Neutral\", \"Positive\"],\n        \"label_thresholds\": [0, 0.5, 0.7, 1]\n    }\n}\n\nresults = inspeq_eval.evaluate_llm_task(\n    metrics_list=[\"RESPONSE_TONE\"],\n    input_data=input_data,\n    task_name=\"custom_config_task\",\n    metrics_config=metrics_config\n)\n```\n\n## Error Handling\n\nThe SDK uses custom exceptions for different types of errors:\n\n- **APIError:** For API related issues\n- **ConfigError:** For invalid config related issues\n- **InputError:** For invalid input data\n\n## Additional Resources\n\nFor detailed API documentation, visit [Inspeq Documentation](https://docs.inspeq.ai).\nFor support or questions, contact our support team through the Inspeq App.\n\n## License\n\nThis SDK is distributed under the terms of the Apache License 2.0.\n"}