{
  "data": "---\nlayout: sp25\ntitle: \"Advanced Large Language Model Agents\"\npermalink: /sp25\nredirect_from:\n - /\n - /s25\n---\n\n<div style=\"border: 2px solid #4CAF50; padding: 20px; background-color: #E9F8E8;\">\n    <p style=\"font-size: 30px; font-weight: bold; color: #4CAF50;\">Announcement:</p>\n    <p style=\"font-size: 25px; color: #333;\">Sign up and learn more about the Agentic AI Summit <a href=\"https://rdi.berkeley.edu/events/agentic-ai-summit\" style=\"color: #4CAF50; font-weight: bold;\">here</a>!</p>\n</div>\n\n### Prospective Students\n\n- This course has completed. Video lectures can still be found in the syllabus below. Join our <a href=\"https://discord.gg/NWVpQ9rBvd\">LLM Agents Discord</a> to stay updated on future MOOCs.\n- This course is built upon the fundamentals from the [Fall 2024 LLM Agents MOOC](https://llmagents-learning.org/f24).\n- All certificates have been released! Thank you for a great semester.\n\n## Course Staff\n\n<table>\n<tbody>\n<tr>\n<td>Instructor</td>\n<td>(Guest) Co-instructor</td>\n<td>(Guest) Co-instructor</td>\n</tr>\n<tr>\n<td><img src=\"assets/dawn-berkeley.jpg\" height=200/></td>\n<td><img src=\"assets/XinyunChen.jpg\" height=200/></td>\n<td><img src=\"assets/KaiyuYang.jpg\" height=200/></td>\n</tr>\n<tr>\n<td><a href=\"https://people.eecs.berkeley.edu/~dawnsong/\">Dawn Song</a></td>\n<td>Xinyun Chen</td>\n<td>Kaiyu Yang</td>\n<tr>\n<td>Professor, UC Berkeley</td>\n<td>Research Scientist, <br> Google DeepMind</td>\n<td>Research Scientist, <br> Meta FAIR</td>\n</tr>\n</tr>\n</tbody>\n</table>\n\n## Guest Speakers\n\n<style>\n  .table {\n    width: 100%;\n    table-layout: fixed;\n    border-collapse: collapse;\n  }\n  .table td {\n    width: 25%;\n    text-align: center;\n    vertical-align: top;\n    padding: 10px;\n  }\n</style>\n\n<table class=\"table\">\n<tr>\n<td><img src=\"assets/jason.png\" height=150/></td>\n<td><img src=\"assets/yu.png\" height=150/></td>\n<td><img src=\"assets/hannah.jpg\" height=150/></td>\n</tr>\n\n<tr>\n<td>Jason Weston</td>\n<td>Yu Su</td>\n<td>Hanna Hajishirzi</td>\n</tr>\n \n<tr>\n<td><img src=\"assets/meta.png\" height=40/></td>\n<td><img src=\"assets/ohio-state.png\" height=40/></td>\n<td><img src=\"assets/washington.png\" height=50/></td>\n</tr>\n\n\n\n<tr>\n<td><img src=\"assets/charles.jpg\" height=150/></td>\n<td><img src=\"assets/ruslan.jpg\" height=150/></td>\n<td><img src=\"assets/caiming.jpeg\" height=150/></td>\n</tr>\n\n<tr>\n<td>Charles Sutton</td>\n<td>Ruslan Salakhutdinov</td>\n<td>Caiming Xiong</td>\n</tr>\n \n<tr>\n<td><img src=\"assets/Google Deepmind.png\" height=40/></td>\n<td><img src=\"assets/meta.png\" height=40/></td>\n<td><img src=\"assets/salesforce.png\" height=50/></td>\n</tr>\n\n\n\n<tr>\n<td><img src=\"assets/thomas.jpg\" height=150/></td>\n<td><img src=\"assets/sean.png\" height=150/></td>\n<td><img src=\"assets/swarat.jpeg\" height=150/></td>\n</tr>\n\n<tr>\n<td>Thomas Hubert</td>\n<td>Sean Welleck</td>\n<td>Swarat Chaudhuri</td>\n</tr>\n \n<tr>\n<td><img src=\"assets/Google Deepmind.png\" height=40/></td>\n<td><img src=\"assets/CMU.png\" height=55/></td>\n<td><img src=\"assets/utaustin.png\" height=60/></td>\n</tr>\n\n</table>\n\n## Course Description\n\nLarge language model (LLM) agents have been an important frontier in AI, however, they still fall short critical skills, such as complex reasoning and planning, for solving hard problems and enabling end-to-end applications in real-world scenarios. Building on our [previous course](https://llmagents-learning.org/f24), this course dives deeper into advanced topics in LLM agents, focusing on reasoning, AI for mathematics, code generation, and program verification. We begin by introducing advanced inference and post-training techniques for building LLM agents that can search and plan. Then, we focus on two application domains: mathematics and programming. We study how LLMs can be used to prove mathematical theorems, as well as generate and reason about computer programs. Specifically, we will cover the following topics:\n- Inference-time techniques for reasoning\n- Post-training methods for reasoning\n- Search and planning\n- Agentic workflow, tool use, and functional calling\n- LLMs for code generation and verification\n- LLMs for mathematics: data curation, continual pretraining, and finetuning\n- LLM agents for theorem proving and autoformalization\n\n## Syllabus\n\n| Date   | Guest Lecture <br> (4:00PM-6:00PM PT) | Supplemental Readings | \n|--------|-------|-------|\n| Jan 27th | **Inference-Time Techniques for LLM Reasoning** <br> Xinyun Chen, Google DeepMind <br> [Livestream](https://www.youtube.com/live/g0Dwtf3BH-0) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/llm-agents-berkeley-intro-sp25.pdf\">Intro</a> <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/inference_time_techniques_lecture_sp25.pdf\">Slides</a> [Quiz 1](https://forms.gle/c6Zz5kGPUzkNTQiq9)  | - [Large Language Models as Optimizers](https://arxiv.org/abs/2309.03409) <br> - [Large Language Models Cannot Self-Correct Reasoning Yet](https://arxiv.org/abs/2310.01798) <br> - [Teaching Large Language Models to Self-Debug](https://arxiv.org/abs/2304.05128) |   \n| Feb 3rd | **Learning to reason with LLMs** <br> Jason Weston, Meta <br> [Livestream](https://www.youtube.com/live/_MNlLhU33H0) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/Jason-Weston-Reasoning-Alignment-Berkeley-Talk.pdf\">Slides</a> [Quiz 2](https://forms.gle/BSmjwfzAtq5hP4GQ8) | - [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290) <br> - [Iterative Reasoning Preference Optimization](https://arxiv.org/abs/2404.19733) <br> - [Chain-of-Verification Reduces Hallucination in Large Language Models](https://arxiv.org/abs/2309.11495) |   \n| Feb 10th | **On Reasoning, Memory, and Planning of Language Agents** <br> Yu Su, Ohio State University <br> [Livestream](https://www.youtube.com/live/zvI4UN2_i-w) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/language_agents_YuSu_Berkeley.pdf\">Slides</a> [Quiz 3](https://forms.gle/D6QogFcZ7xMNFzvo9) | - [Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization](https://arxiv.org/abs/2405.15071) <br> - [HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models](https://arxiv.org/abs/2405.14831) <br> - [Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents](https://arxiv.org/abs/2411.06559) |   \n| Feb 17th | *No Class - Presidents' Day*  | |   \n| Feb 24th | **Open Training Recipes for Reasoning in Language Models** <br> Hanna Hajishirzi, University of Washington <br> [Livestream](https://www.youtube.com/live/cMiu3A7YBks) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/OLMo-Tulu-Reasoning-Hanna.pdf\">Slides</a> [Quiz 4](https://forms.gle/WV9v2NkphN38pzoU8) | - [Tulu 3: Pushing Frontiers in Open Language Model Post-Training](https://arxiv.org/abs/2411.15124) <br> - [Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback](https://arxiv.org/abs/2406.09279) <br> - [OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs](https://arxiv.org/abs/2411.14199) |   \n| Mar 3rd | **Coding Agents and AI for Vulnerability Detection** <br> Charles Sutton, Google DeepMind <br> [Livestream](https://www.youtube.com/live/JCk6qJtaCSU) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/Code Agents and AI for Vulnerability Detection.pdf\">Slides</a> [Quiz 5](https://forms.gle/ZCn8FZDas1VU6GrG7) | - [Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities](https://arxiv.org/abs/2409.16165) <br> - [From Naptime to Big Sleep: Using Large Language Models To Catch Vulnerabilities In Real-World Code](https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html) |   \n| Mar 10th | **Multimodal Autonomous AI Agents** <br> Ruslan Salakhutdinov, CMU/Meta <br> [Livestream](https://www.youtube.com/live/RPINOYM12RU) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/ruslan-multimodal.pdf\">Slides</a> [Quiz 6](https://forms.gle/tpoXSkTZKChXr67q9) | - [Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070) <br> - [WebArena: A Realistic Web Environment for Building Autonomous Agents](https://arxiv.org/abs/2307.13854) <br> - [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://jykoh.com/vwa) <br> - [Tree Search for Language Model Agents](https://jykoh.com/search-agents) |   \n| Mar 17th | **Multimodal Agents – From Perception to Action** <br> Caiming Xiong, Salesforce AI Research <br> [Livestream](https://www.youtube.com/live/n__Tim8K2IY) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/Multimodal_Agent_caiming.pdf\">Slides</a> [Quiz 7](https://forms.gle/WksK2qeXsZp8iY7YA) | - [OSWORLD: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://arxiv.org/pdf/2404.07972) <br> - [AGUVIS: Unified Pure Vision Agents For Autonomous GUI Interaction](https://arxiv.org/pdf/2412.04454) |\n| Mar 24th | *No Class - Spring Recess*  | |   \n| Mar 31st | **AlphaProof: when reinforcement learning meets formal mathematics** <br> Thomas Hubert, Google DeepMind <br> <span style=\"color:red\">10am-noon PT</span> <br> [Livestream](https://www.youtube.com/live/3gaEMscOMAU) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/alphaproof.pdf\">Slides</a> [Quiz 8](https://forms.gle/yzLSNHxNRgULpyoe9) | - [AI achieves silver-medal standard solving International Mathematical Olympiad problems](https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/) <br> - [Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](https://arxiv.org/pdf/1712.01815) <br> - [The Future of Mathematics?](https://www.youtube.com/watch?v=Dp-mQ3HxgDE) <br> - [Building the Mathematical Library of the Future](https://www.quantamagazine.org/building-the-mathematical-library-of-the-future-20201001/) |   \n| Apr 7th | **Language models for autoformalization and theorem proving** <br> Kaiyu Yang, Meta FAIR <br> [Livestream](https://www.youtube.com/live/cLhWEyMQ4mQ) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/mathverification.pdf\">Slides</a> [Quiz 9](https://forms.gle/oXmRWhwYN9vPp6AV7) | - [LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://arxiv.org/abs/2306.15626) <br> - [Autoformalization with Large Language Models](https://arxiv.org/abs/2205.12615) <br> - [Autoformalizing Euclidean Geometry](https://arxiv.org/abs/2405.17216) |   \n| Apr 14th | **Bridging Informal and Formal Mathematical Reasoning** <br> Sean Welleck, CMU <br> [Livestream](https://www.youtube.com/live/Gy5Nm17l9oo) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/welleck2025_berkeley_bridging.pdf\">Slides</a> [Quiz 10](https://forms.gle/jumLYzywCcG2Vy6v9) | - [Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs](https://arxiv.org/abs/2210.12283) <br> - [miniCTX: Neural Theorem Proving with Long-Contexts](https://www.arxiv.org/pdf/2408.03350) <br> - [Lean-STaR: Learning to Interleave Thinking and Proving](https://arxiv.org/abs/2407.10040) <br> - [ImProver: Agent-Based Automated Proof Optimization](https://arxiv.org/abs/2410.04753) |   \n| Apr 21st | **Abstraction and Discovery with Large Language Model Agents** <br> Swarat Chaudhuri, UT Austin <br> <span style=\"color:red\">10am-noon PT</span> <br> [Livestream](https://www.youtube.com/live/IHc0TEMrEdY) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/swarat.pdf\">Slides</a> [Quiz 11](https://forms.gle/k3t47MnBxUZDUnXt9) | -[An In-Context Learning Agent for Formal Theorem-Proving](https://arxiv.org/abs/2310.04353) <br> - [Symbolic Regression with a Learned Concept Library](https://arxiv.org/abs/2409.09359) |   \n| Apr 28th | **Towards building safe and secure agentic AI** <br> Dawn Song, UC Berkeley <br> [Livestream](https://www.youtube.com/live/ti6yPE2VPZc) <a href=\"https://rdi.berkeley.edu/llm-agents-mooc/slides/dawn-agentic-ai.pdf\">Slides</a> [Quiz 12](https://forms.gle/dkuUHdYmbKTd1KNu7) | - [Privtrans: Automatically Partitioning Programs for Privilege Separation](https://dawnsong.io/papers/privtrans.pdf) <br> - [DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks](https://arxiv.org/abs/2504.11358) <br> - [AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases](https://arxiv.org/abs/2407.12784) <br> - [Progent: Programmable Privilege Control for LLM Agents](https://arxiv.org/html/2504.11703v1) |   \n\n## Completion Certificate\n\n_All of the instructions below are also provided in this [Google Doc format](https://docs.google.com/document/d/1t4HS15dySldeElgDbtKmM3piInllq_auHtpO-SRScjo/edit?usp=sharing) for your convinience._\n\nLLM Agent course completion certificates will be awarded to students based on the rules of the following tiers. **All assignments are due on May 31st at 11:59pm PDT.** _All assignments should send a Google Forms confirmation email on successful submission._\n\nAll students will need to complete a [Certificate Declaration Form](https://forms.gle/iPA2MUpHdtrBE1vu5) by May 31st at 11:59pm PDT.\n\n**Trailblazer Tier:**\n- Complete all 12 quizzes associated with each lecture\n- Pass the written article assignment\n\n**Mastery Tier:**\n- Complete all 12 quizzes associated with each lecture\n- Pass the written article assignment\n- Pass all lab assignments\n\n**Ninja Tier:**\n- Complete all 12 quizzes associated with each lecture\n- Pass the written article assignment\n- Submit a project to the [AgentX competition](https://rdi.berkeley.edu/agentx/)\n\n**Legendary Tier:**\n- Complete all 12 quizzes associated with each lecture\n- Pass the written article assignment\n- Become a prize winner or finalist at the [AgentX competition](https://rdi.berkeley.edu/agentx/)\n\n**Honorary Tier:**\n- For the most helpful/supportive students in discord!\n\n_NOTE: completing the assignments associated with this course in order to earn a Completion Certificate is completely optional. You are more than welcome to just watch the lectures and audit the course!_\n\n## Coursework\n\nIMPORTANT: Please use the same email address to submit all coursework, the certificate declaration form, and the initial signup form as this is how we track your progress throughout the course!\n\n### Quizzes\n\nAll quizzes are released shortly after the corresponding lecture. Please remember to complete the quiz each week. Although it’s graded on completion, we encourage you to do your best. There are 5 multiple choice questions per quiz. \n\nThe quizzes are posted in the Syllabus section. Answers will be shared when we release the next quiz. _Click on previous quiz links to access the \"view score\" button._\n\nAn archive of all quizzes can be found [here](https://docs.google.com/document/d/1A00cUWux-J0p9AOnwpyNN3Rb5QFRsbBgAmvgPMezJ10/edit?usp=sharing).\n\n### Written Article\n\nCreate a social media post (X/LinkedIn/etc) of roughly 500 words. Include the link to our MOOC website in the article and tweet.\n- Students in the Trailblazer or Mastery Tier should either summarize information from one of the lecture(s) or write a postmortem on their learning experience during our MOOC\n- Students in the Ninja or Legendary Tier should write about their AgentX submission\n\nThe written article is an effort-based assignment that will be graded as pass or no pass (P/NP). \n\n| [Submission Form](https://forms.gle/399VqBP88WL1AJ4J6) |\n\n### Labs\n\nThere are two labs to give students experience with verificable code generation agents using Lean. Students must pass both labs to recieve credit towards the Mastery Tier Certificate. Please read the [Lab FAQs](https://docs.google.com/document/d/1AmVd4tU8wvYlINDmUuEuw6TIvxl95yjgui9JZAZ8P80/edit?usp=sharing) before asking any questions in our [LLM Agents Discord](https://discord.gg/NWVpQ9rBvd).\n\n| [Instructions & Starter Code](https://drive.google.com/drive/folders/1DsXvOqfvFs4yBc2ZrLuOCXAFXBb5q1kg?usp=sharing) | [Labs Submission Form](https://docs.google.com/forms/d/e/1FAIpQLSd3Sx9MFRAsfuIZMrF4w-c85DL0Ek-0nVtdp6L81-12eiHXng/viewform?usp=sharing) |\n\n### Project\n\nCheck out our AgentX competition [website](https://rdi.berkeley.edu/agentx/). Every member of the team should sign up individually [here](https://forms.gle/iiszq2tBAFugfGqp8). There are no limits to team sizes.\n\nTwo Tracks:\n- Entrepreneurship: Build agent-powered products & startups\n- Research: Explore the frontiers of LLM Agents technology\n\nSelect students will be given mentorship by Berkeley postdocs/mentors on an AgentX Research Track project. Apply [here](https://forms.gle/E2D69euNBjSmYsK28). DUE March 26th at 11:59pm PDT. _NOTE: Mentorship is not required to join or succeed in AgentX._\n\nFinal submissions are due May 31st. Please ask any questions and find potential team members in our [LLM Agents Discord](https://discord.gg/NWVpQ9rBvd). \n\n"
}
