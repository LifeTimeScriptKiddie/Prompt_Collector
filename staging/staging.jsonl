={"data":"- LLaMA 3\n   - Llama System Safety:\n   - Models & Inference Guardrails: Llama-Guard-3 8B (multilingual text in)\n   - Prompt Guard (direct and indirect prompt injection filtering)\n   - Cybersecurity: CyberSec Eval 3, a new benchmark for assessing LLM security risks, introducing tests for prompt injection and code interpreter abuse, revealing unresolved conditioning    issues, proposing the False Refusal Rate (FRR) to measure safety-utility tradeoffs, and providing open-source code for further evaluations.\n \n \n-   <b>Umar Jamil</b>\n   -   [Coding LLaMA 2 from scratch in PyTorch - KV Cache, Grouped Query Attention, Rotary PE, RMSNorm](https://www.youtube.com/watch?v=oM4VmoabDAI)\n   -   [GitHub](https://github.com/hkproj/pytorch-llama)\n   -   [Pdf](https://github.com/hkproj/pytorch-llama/blob/main/Slides.pdf)\n    \n-   <b>cameronr wolfe</b>\n   -   [LLaMA-2 from the Ground Up](https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up)\n   -   [practical-prompt-engineering-part](https://cameronrwolfe.substack.com/p/practical-prompt-engineering-part)\n    \n"}